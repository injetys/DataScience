{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision_Tree-Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGWX1suDerwz"
      },
      "source": [
        "# Decision Trees and Neural Networks\n",
        "\n",
        "We will first be looking at decision trees which allow us to sort samples into categories based on questions we ask about the sample attributes.\n",
        "\n",
        "Suppose we are asked to build a decision tree based on the experience of our company in hiring candidates.  The data we are supplied with consists of a tuple of (`input`, `label`) pairs.  The `label` tells us if the candidate was hired or not, whereas the `input` is a dictionary of the attribues: level, primary programming language, active twitter user and whether they have a Ph.D."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpo3WC9Berw2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "hire_data = [\n",
        "    ({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'no'},    False),\n",
        "    ({'level':'Senior', 'lang':'Java', 'tweets':'no', 'phd':'yes'},   False),\n",
        "    ({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'no'},      True),\n",
        "    ({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'no'},   True),\n",
        "    ({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'no'},       True),\n",
        "    ({'level':'Junior', 'lang':'R', 'tweets':'yes', 'phd':'yes'},     False),\n",
        "    ({'level':'Mid', 'lang':'R', 'tweets':'yes', 'phd':'yes'},         True),\n",
        "    ({'level':'Senior', 'lang':'Python', 'tweets':'no', 'phd':'no'},  False),\n",
        "    ({'level':'Senior', 'lang':'R', 'tweets':'yes', 'phd':'no'},       True),\n",
        "    ({'level':'Junior', 'lang':'Python', 'tweets':'yes', 'phd':'no'},  True),\n",
        "    ({'level':'Senior', 'lang':'Python', 'tweets':'yes', 'phd':'yes'}, True),\n",
        "    ({'level':'Mid', 'lang':'Python', 'tweets':'no', 'phd':'yes'},     True),\n",
        "    ({'level':'Mid', 'lang':'Java', 'tweets':'yes', 'phd':'no'},       True),\n",
        "    ({'level':'Junior', 'lang':'Python', 'tweets':'no', 'phd':'yes'}, False)\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dad2SQsLerw7"
      },
      "source": [
        "In order to build a decision tree to sort new applicants, we can follow a greedy algorithm to find the best decision nodes.\n",
        "\n",
        "**Step 1:** If the data all have the same label, create a leaf node that predicts the label and then stop.\n",
        "\n",
        "- Nope, there are a bunch of \"False\" and \"True\" labels currently, so we need to continue.\n",
        "\n",
        "**Step 2:** If the list of attributes is empty (no more possible questions to ask) create a leaf node that predicts the most common label and then stop.\n",
        "\n",
        "- No, we are just getting started.\n",
        "\n",
        "**Step 3:** Partition the data by each of the attributes and calculate the partition entropy.\n",
        "\n",
        "- Ok, now we can get to work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePOZroEderw8"
      },
      "source": [
        "Remember that the entropy of a set $S$ that can be divided up into a number of classes $C_1, C_2, \\ldots, C_n$ is\n",
        "\n",
        "$$ H(S) = -p_1 \\log_2 p_1 - p_2 \\log_2 p_2 - \\ldots - p_n \\log_2 p_n $$\n",
        "\n",
        "where $p_n$ is the proportion of the data belonging to class $C_n$\n",
        "\n",
        "Then, the entropy of a partition (question that divides the data into sets) is \n",
        "\n",
        "$$ H = q_1H(S_1) + \\ldots + q_mH(S_m) $$\n",
        "\n",
        "where $q_m$ is the proportion of the data in set $S_n$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu7ATVP8erw9"
      },
      "source": [
        "Let's start with the attribute `level`.  If we partition on level, there are 3 possibilities: Senior, Mid, and Junior.  These 3 are our sets.  'True' and 'False' are the classes those set items fall into.  So now we can calculate our $p$ and $q$ values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOgfaeKgerw-"
      },
      "source": [
        "# Define a function to calculate the entropy of a set, given\n",
        "# the proportion of data in each class (p_1 ... p_n)\n",
        "# By convention, the entropy of an empty class is zero.\n",
        "\n",
        "def entropy(pvec):\n",
        "    H = 0\n",
        "    for p in pvec:\n",
        "        if p != 0: \n",
        "            H += -p*np.log2(p)\n",
        "            \n",
        "    return H"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMGKXyh3erxB"
      },
      "source": [
        "# Define a function to calculate the entropy of a partition\n",
        "# given an attribute to perform the partition, the possible\n",
        "# values of the attribute, and the data set\n",
        "\n",
        "def entropy_part(attr, sets, data):\n",
        "    \"\"\"\n",
        "    H_part = entropy_part(attr, sets, data)\n",
        "    calculates the entropy of a partition\n",
        "    INPUTS: attr - attribute of the partition\n",
        "            sets - list of possible values of the attribute\n",
        "            data - input data \n",
        "    \"\"\"\n",
        "    q = np.zeros(len(sets))\n",
        "    H = np.zeros(len(sets))\n",
        "\n",
        "    nrecords = len(data)\n",
        "\n",
        "    set_index = 0\n",
        "    for S in sets:\n",
        "        \n",
        "        # There are two classes, true and false\n",
        "        set_true = 0\n",
        "        set_false = 0\n",
        "        p_class = np.zeros(2)\n",
        "        \n",
        "        for samp in data:\n",
        "            if samp[0][attr] == S:\n",
        "                if samp[1] == True:\n",
        "                    set_true += 1\n",
        "                else:\n",
        "                    set_false += 1\n",
        "        \n",
        "        nsamps = set_true + set_false\n",
        "        if nsamps != 0:\n",
        "            # proportion of samples in the true class per set\n",
        "            p_class[0] = set_true/(nsamps)\n",
        "            # proportion of samples in the false class per set\n",
        "            p_class[1] = set_false/(nsamps)\n",
        "    \n",
        "        H[set_index] = np.sum(entropy(p_class))\n",
        "        \n",
        "        if nrecords != 0:\n",
        "            q[set_index] = nsamps/nrecords\n",
        "    \n",
        "        set_index += 1\n",
        "    \n",
        "    H_part = np.dot(q,H)\n",
        "  \n",
        "    return H_part  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOCDXGZkerxF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e12c4f91-8f5f-4ef2-e719-b4a7e929b899"
      },
      "source": [
        "attr = 'level'\n",
        "sets = ['Senior', 'Mid', 'Junior']\n",
        "\n",
        "H_part = entropy_part(attr, sets, hire_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropy of level partition is 0.6935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzrZMnPverxJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07a0e8de-8f8d-4bdc-c90d-d252b947d280"
      },
      "source": [
        "attr = 'lang'\n",
        "sets = ['Java', 'R', 'Python']\n",
        "\n",
        "H_part = entropy_part(attr, sets, hire_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropy of lang partition is 0.8601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uF8_K-XerxO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b94aeab-5a6e-4504-9ce4-f9c0f17b75b0"
      },
      "source": [
        "attr = 'tweets'\n",
        "sets = ['yes', 'no']\n",
        "\n",
        "H_part = entropy_part(attr, sets, hire_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropy of tweets partition is 0.7885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqkRnIa9erxS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33393b13-c966-4679-e4e3-4d3ae54fdd78"
      },
      "source": [
        "attr = 'phd'\n",
        "sets = ['yes', 'no']\n",
        "\n",
        "H_part = entropy_part(attr, sets, hire_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropy of phd partition is 0.8922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOPHKrzOerxW"
      },
      "source": [
        "**Step 4:** Select the partition with the lowest entropy\n",
        "\n",
        "- The `level` attribute partition gives the lowest entropy\n",
        "\n",
        "**Step 5:** Add a decision node based on the chosen attribute\n",
        "\n",
        "- We would add a level decision node.\n",
        "\n",
        "Now our decision tree looks like this:\n",
        "\n",
        "<img src=\"https://www.andrews.edu/~tzs/DataScience/decisiontree1.png\" width=250>\n",
        "\n",
        "\n",
        "**Step 6:** Apply steps 1-6 on all subsets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NJpxG39erxY"
      },
      "source": [
        "# Break the data up into subsets\n",
        "\n",
        "lev_senior_data = [record for record in hire_data if record[0]['level'] == 'Senior']\n",
        "lev_mid_data = [record for record in hire_data if record[0]['level'] == 'Mid']\n",
        "lev_junior_data = [record for record in hire_data if record[0]['level'] == 'Junior']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqKBCRpeerxe"
      },
      "source": [
        "Let's start with the level = 'Senior' set.\n",
        "\n",
        "**Step 1:** Do the data have the same label class?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAo2dh5Zerxf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "30eb6c9d-3187-4e62-c54d-28377325f820"
      },
      "source": [
        "lev_senior_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'lang': 'Java', 'level': 'Senior', 'phd': 'no', 'tweets': 'no'}, False),\n",
              " ({'lang': 'Java', 'level': 'Senior', 'phd': 'yes', 'tweets': 'no'}, False),\n",
              " ({'lang': 'Python', 'level': 'Senior', 'phd': 'no', 'tweets': 'no'}, False),\n",
              " ({'lang': 'R', 'level': 'Senior', 'phd': 'no', 'tweets': 'yes'}, True),\n",
              " ({'lang': 'Python', 'level': 'Senior', 'phd': 'yes', 'tweets': 'yes'}, True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VROAf6GJerxj"
      },
      "source": [
        "No, there is a mixture of 'True' and 'False' labels.\n",
        "\n",
        "**Step 2:** List of attributes used up?  - no\n",
        "\n",
        "**Step 3:** Partition on remaining attributes and calculate partition entropy.\n",
        "\n",
        "**Step 4:** Select the attribute with the lowest partition entropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7LNoEenerxk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8549b510-a8ec-4662-8b66-401f1533f17a"
      },
      "source": [
        "attr = 'lang'\n",
        "sets = ['Java', 'R', 'Python']\n",
        "\n",
        "H_part = entropy_part(attr, sets, lev_senior_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))\n",
        "\n",
        "attr = 'tweets'\n",
        "sets = ['yes', 'no']\n",
        "\n",
        "H_part = entropy_part(attr, sets, lev_senior_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))\n",
        "\n",
        "attr = 'phd'\n",
        "sets = ['yes', 'no']\n",
        "\n",
        "H_part = entropy_part(attr, sets, lev_senior_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropy of lang partition is 0.4000\n",
            "Entropy of tweets partition is 0.0000\n",
            "Entropy of phd partition is 0.9510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pGlWqO0erxp"
      },
      "source": [
        "Tweets is the winner!\n",
        "\n",
        "**Step 5:** Add a decision node based on the chosen attribute.\n",
        "\n",
        "Now our decision tree looks like this\n",
        "\n",
        "<img src='https://www.andrews.edu/~tzs/DataScience/decisiontree2.png' width=300>\n",
        "\n",
        "**Step 6:** Apply steps 1-6 on all subsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1WSHkG9erxq"
      },
      "source": [
        "# Break data into subsets\n",
        "lev_senior_tweets_y = [record for record in lev_senior_data if record[0]['tweets'] == 'yes']\n",
        "lev_senior_tweets_n = [record for record in lev_senior_data if record[0]['tweets'] == 'no']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcr9Hrt6erxt"
      },
      "source": [
        "Look at the 'tweets' = 'yes' subset\n",
        "\n",
        "**Step 1:** Do the data have the same level class?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5ovvXpLerxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e3660800-972d-4deb-a6eb-b4c93c5022a4"
      },
      "source": [
        "lev_senior_tweets_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'lang': 'R', 'level': 'Senior', 'phd': 'no', 'tweets': 'yes'}, True),\n",
              " ({'lang': 'Python', 'level': 'Senior', 'phd': 'yes', 'tweets': 'yes'}, True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds9qz19aerxw"
      },
      "source": [
        "Yes! Create a leaf node and then stop\n",
        "\n",
        "The same goes for the 'tweets' = 'no' subset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q82yWeI8erxw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fe947240-80c9-4794-8d3e-8eb586eba2ef"
      },
      "source": [
        "lev_senior_tweets_n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'lang': 'Java', 'level': 'Senior', 'phd': 'no', 'tweets': 'no'}, False),\n",
              " ({'lang': 'Java', 'level': 'Senior', 'phd': 'yes', 'tweets': 'no'}, False),\n",
              " ({'lang': 'Python', 'level': 'Senior', 'phd': 'no', 'tweets': 'no'}, False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Us5xhwBerxz"
      },
      "source": [
        "So now we are done with the level = 'Senior' branch of our decision tree, which looks like this:\n",
        "\n",
        "<img src='https://www.andrews.edu/~tzs/DataScience/decisiontree3.png' width=350>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaYIPfL5erx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "15e9fe44-d186-4c49-e235-faa423ce390e"
      },
      "source": [
        "# Task 1: Apply the greedy algorithm to the level = 'Mid' set to \n",
        "# fill out that part of the decision tree\n",
        "\n",
        "lev_mid_data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'lang': 'Python', 'level': 'Mid', 'phd': 'no', 'tweets': 'no'}, True),\n",
              " ({'lang': 'R', 'level': 'Mid', 'phd': 'yes', 'tweets': 'yes'}, True),\n",
              " ({'lang': 'Python', 'level': 'Mid', 'phd': 'yes', 'tweets': 'no'}, True),\n",
              " ({'lang': 'Java', 'level': 'Mid', 'phd': 'no', 'tweets': 'yes'}, True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZFqdkJ7erx3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c26e22c4-e527-4815-e2f2-e0e2e4acf3c2"
      },
      "source": [
        "# Task 2: Apply the greedy algorithm to the level = 'Junior' set\n",
        "# to fill out that part of the decision tree\n",
        "\n",
        "lev_junior_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'lang': 'Python', 'level': 'Junior', 'phd': 'no', 'tweets': 'no'}, True),\n",
              " ({'lang': 'R', 'level': 'Junior', 'phd': 'no', 'tweets': 'yes'}, True),\n",
              " ({'lang': 'R', 'level': 'Junior', 'phd': 'yes', 'tweets': 'yes'}, False),\n",
              " ({'lang': 'Python', 'level': 'Junior', 'phd': 'no', 'tweets': 'yes'}, True),\n",
              " ({'lang': 'Python', 'level': 'Junior', 'phd': 'yes', 'tweets': 'no'}, False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II73JNAmgBt_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d43d07d0-9710-40c6-8a4e-8dfbbfc13d43"
      },
      "source": [
        "attr = 'lang'\n",
        "sets = ['Java', 'R', 'Python']\n",
        "\n",
        "H_part = entropy_part(attr, sets, lev_junior_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))\n",
        "\n",
        "attr = 'tweets'\n",
        "sets = ['yes', 'no']\n",
        "\n",
        "H_part = entropy_part(attr, sets, lev_junior_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))\n",
        "\n",
        "attr = 'phd'\n",
        "sets = ['yes', 'no']\n",
        "\n",
        "H_part = entropy_part(attr, sets, lev_junior_data)\n",
        "\n",
        "print('Entropy of {} partition is {:.4f}'.format(attr, H_part))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entropy of lang partition is 0.9510\n",
            "Entropy of tweets partition is 0.9510\n",
            "Entropy of phd partition is 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s2CwkltgKLg"
      },
      "source": [
        "# Break data into subsets\n",
        "lev_junior_tweets_y = [record for record in lev_junior_data if record[0]['phd'] == 'yes']\n",
        "lev_junior_tweets_n = [record for record in lev_junior_data if record[0]['phd'] == 'no']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-q3jDRomNfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29e801f2-99ee-40da-d7ba-c6f24d8901b6"
      },
      "source": [
        "lev_junior_tweets_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'lang': 'R', 'level': 'Junior', 'phd': 'yes', 'tweets': 'yes'}, False),\n",
              " ({'lang': 'Python', 'level': 'Junior', 'phd': 'yes', 'tweets': 'no'}, False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUsqQ_cegQkx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "68b302f2-683d-4915-c6bd-f95cbaa2a2d3"
      },
      "source": [
        "lev_junior_tweets_n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'lang': 'Python', 'level': 'Junior', 'phd': 'no', 'tweets': 'no'}, True),\n",
              " ({'lang': 'R', 'level': 'Junior', 'phd': 'no', 'tweets': 'yes'}, True),\n",
              " ({'lang': 'Python', 'level': 'Junior', 'phd': 'no', 'tweets': 'yes'}, True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz1RlQGaerx5"
      },
      "source": [
        "# Task 3: Complete the ascii art decision tree below, showing your\n",
        "# completed tree\n",
        "\n",
        "\"\"\"\n",
        "                      L E V E L\n",
        "                 /        |       \\\n",
        "               Senior    Mid    Junior\n",
        "               /          |         \\\n",
        "            tweets       hire       phd\n",
        "             / \\                    / \\\n",
        "           yes  no               yes   no\n",
        "           /     \\                /     \\ \n",
        "       hire    no hire         no hire  hire\n",
        "\"\"\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTwDGxyeerx7"
      },
      "source": [
        "## Neural Networks\n",
        "\n",
        "We will be building a neural network to defeat a too-simple CAPCHA.  The CAPCHA consists of a picture of a single digit, made up of 25 pixels.  We want our nural network to take as input those pixel values and output the number that it correponds to.\n",
        "\n",
        "Our training data inputs will consist of all of the possible numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xGEPQRIerx8"
      },
      "source": [
        "zero_digit = [1,1,1,1,1,  # the 1s are the pixels that are dark\n",
        "              1,0,0,0,1,  # can you see the zero?\n",
        "              1,0,0,0,1,\n",
        "              1,0,0,0,1,\n",
        "              1,1,1,1,1]\n",
        "\n",
        "one_digit = [0,0,1,0,0, #   *\n",
        "             0,0,1,0,0, #   *\n",
        "             0,0,1,0,0, #   *\n",
        "             0,0,1,0,0, #   *\n",
        "             0,0,1,0,0] #   *\n",
        "\n",
        "two_digit = [1,1,1,1,1, # *****\n",
        "             0,0,0,0,1, #     *\n",
        "             1,1,1,1,1, # *****\n",
        "             1,0,0,0,0, # *\n",
        "             1,1,1,1,1] # *****\n",
        "\n",
        "thr_digit = [1,1,1,1,1, # *****\n",
        "             0,0,0,0,1, #     *\n",
        "             1,1,1,1,1, # *****\n",
        "             0,0,0,0,1, #     *\n",
        "             1,1,1,1,1] # *****\n",
        "\n",
        "fou_digit = [1,0,0,0,1, # *   *\n",
        "             1,0,0,0,1, # *   *\n",
        "             1,1,1,1,1, # *****\n",
        "             0,0,0,0,1, #     *\n",
        "             0,0,0,0,1] #     *\n",
        "\n",
        "fiv_digit = [1,1,1,1,1, # *****\n",
        "             1,0,0,0,0, # *    \n",
        "             1,1,1,1,1, # *****\n",
        "             0,0,0,0,1, #     *\n",
        "             1,1,1,1,1] # *****\n",
        "\n",
        "six_digit = [1,1,1,1,1, # *****\n",
        "             1,0,0,0,0, # *    \n",
        "             1,1,1,1,1, # *****\n",
        "             1,0,0,0,1, # *   *\n",
        "             1,1,1,1,1] # *****\n",
        "\n",
        "sev_digit = [1,1,1,1,1, # *****\n",
        "             0,0,0,0,1, #     *\n",
        "             0,0,0,0,1, #     *\n",
        "             0,0,0,0,1, #     *\n",
        "             0,0,0,0,1] #     *\n",
        "            \n",
        "eig_digit = [1,1,1,1,1, # *****\n",
        "             1,0,0,0,1, # *   *\n",
        "             1,1,1,1,1, # *****\n",
        "             1,0,0,0,1, # *   *\n",
        "             1,1,1,1,1] # *****\n",
        "\n",
        "nin_digit = [1,1,1,1,1, # *****\n",
        "             1,0,0,0,1, # *   *\n",
        "             1,1,1,1,1, # *****\n",
        "             0,0,0,0,1, #     *\n",
        "             1,1,1,1,1] # *****\n",
        "\n",
        "inputs = [zero_digit, one_digit, two_digit, thr_digit,\n",
        "          fou_digit, fiv_digit, six_digit, sev_digit,\n",
        "          eig_digit, nin_digit]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNXLBaVderx9"
      },
      "source": [
        "We want our output to indicate which digit the neural network thinks it is, so we'll need 10 outputs.  The correct output for digit 4, for instance, would be:\n",
        "\n",
        "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
        "\n",
        "so assuming the inputs are ordered from 0 to 9, the corresponding target outputs would be:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-XNZPzPerx_"
      },
      "source": [
        "targets = [[1 if i == j else 0 for i in range(10)] for j in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkmo4_9ReryB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "469a7134-29c9-4b52-ac5f-1bc0f9102439"
      },
      "source": [
        "print(targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3pIG-h0eryE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8baa8343-2046-4d5b-d1ab-817af056e9a1"
      },
      "source": [
        "print(targets[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyZAtI6NeryI"
      },
      "source": [
        "Now we are ready to build our neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylzMCNcferyJ"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(0)   # to get repeatable results\n",
        "input_size = 25  # each input is a vector of length 25 (pixels)\n",
        "num_hidden = 5   # 5 neurons in the hidden layer\n",
        "output_size = 10 # output vector of length 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Bx5GzreryL"
      },
      "source": [
        "# Each hidden neuron has one weight per input, plus a bias weight\n",
        "\n",
        "hidden_layer = [[random.random() for _ in range(input_size + 1)]\n",
        "                for _ in range(num_hidden)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMkoWqW2eryM"
      },
      "source": [
        "# Each output neuron has one weight per hidden neuron, plus a bias weight\n",
        "\n",
        "output_layer = [[random.random() for _ in range(num_hidden + 1)]\n",
        "                for _ in range(output_size)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqpdquoIeryO"
      },
      "source": [
        "# The network starts out with random weights\n",
        "\n",
        "network = [hidden_layer, output_layer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYlXo1zkeryQ"
      },
      "source": [
        "We have set up our neural network, now we need to train it with our inputs and target outputs.  We can do this with a series of back propagation and feed forward steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSohd7yHeryR"
      },
      "source": [
        "### Feed forward\n",
        "\n",
        "Feeding forward means to run through the neural network, one layer at a time to go from inputs to outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXsFOum7eryR"
      },
      "source": [
        "import math\n",
        "\n",
        "# Define the sigmoid function which returns a zero for inputs\n",
        "# slightly less than zero and a one for inputs slightly greater\n",
        "# than zero and varies smoothly in between.\n",
        "def sigmoid(t):\n",
        "    return 1 / (1 + math.exp(-t))\n",
        "\n",
        "# Compute the neuron output based on weights and inputs\n",
        "def neuron_output(weights, inputs):\n",
        "    return sigmoid(np.dot(weights, inputs))\n",
        "\n",
        "def feed_forward(neural_network, input_vector):\n",
        "    \"\"\"takes in a neural network (represented as a list of \n",
        "    lists of lists of weights) and returns the output from \n",
        "    forward-propagating the input\"\"\"\n",
        "\n",
        "    outputs = []\n",
        "\n",
        "    for layer in neural_network:\n",
        "\n",
        "        input_with_bias = input_vector + [1]             # add a bias input\n",
        "        output = [neuron_output(neuron, input_with_bias) # compute the output\n",
        "                  for neuron in layer]                   # for this layer\n",
        "        outputs.append(output)                           # and remember it\n",
        "\n",
        "        # the input to the next layer is the output of this one\n",
        "        input_vector = output\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il0-LQ-5eryU"
      },
      "source": [
        "Let's try running a feed-forward on our untrained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6A0No-meryV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "61d9acd0-8027-4340-d25e-734b9543eb83"
      },
      "source": [
        "hidden, output = feed_forward(network, inputs[4])\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.927214123782649, 0.8741070411267978, 0.9612981708065071, 0.9694698718136389, 0.9339265462644313, 0.9324102446962134, 0.9390268649713612, 0.8963385066787134, 0.9748845384014487, 0.8617949754010217]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBlgWaUeryX"
      },
      "source": [
        "The output of our neural network is rubbish, but what did we expect?  We haven't trained it yet!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvNyDQ0DeryY"
      },
      "source": [
        "### Backpropagation\n",
        "With backpropagation, we work backwards through our neural network, ajusting the weights so that the desired ouptuts are trained into the network.  Backpropagation iterates over the following algorithm:\n",
        "\n",
        "1. Run feed_forward on an input vector to produce the outputs of all of the neurons in the network.\n",
        "2. This results in an error for each output neuron-the difference between its output and its target.\n",
        "3. Compute the gradient of this error as a function of the neuron's weights and adjust the weights in the direction that most decreases the error.\n",
        "4. \"Propagate\" these output errors backward to infer errors for the hidden layer.\n",
        "5. \"Compute the gradients of these errors and adjust the hidden layer's weights in the same manner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNATeWDFeryZ"
      },
      "source": [
        "def backpropagate(network, input_vector, target):\n",
        "\n",
        "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
        "\n",
        "    # the output * (1 - output) is from the derivative of sigmoid\n",
        "    output_deltas = [output * (1 - output) * (output - target[i])\n",
        "                     for i, output in enumerate(outputs)]\n",
        "\n",
        "    # adjust weights for output layer (network[-1])\n",
        "    for i, output_neuron in enumerate(network[-1]):\n",
        "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
        "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
        "\n",
        "    # back-propagate errors to hidden layer\n",
        "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
        "                      np.dot(output_deltas, [n[i] for n in network[-1]])\n",
        "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
        "\n",
        "    # adjust weights for hidden layer (network[0])\n",
        "    for i, hidden_neuron in enumerate(network[0]):\n",
        "        for j, input in enumerate(input_vector + [1]):\n",
        "            hidden_neuron[j] -= hidden_deltas[i] * input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sP7s4xperyb"
      },
      "source": [
        "Now we can train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWvNVAkSeryf"
      },
      "source": [
        "# 10,000 iterations seems enough to converge\n",
        "for __ in range(10000):\n",
        "    for input_vector, target_vector in zip(inputs, targets):\n",
        "        backpropagate(network, input_vector, target_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEF7VkGperyh"
      },
      "source": [
        "Try again with an input of 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FC7XFdKeryh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a12e6225-bd74-469b-e1a0-1ff8c7c28432"
      },
      "source": [
        "hidden, output = feed_forward(network, inputs[4])\n",
        "print(' '.join('{:.2f}'.format(num) for num in output))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00 0.02 0.01 0.00 0.99 0.00 0.00 0.00 0.00 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUoSRIq9eryj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37f38f2b-bdd5-4b57-8e38-18777bb1a944"
      },
      "source": [
        "# Task 4 Display the neural network ouput for the number 9 input\n",
        "\n",
        "hidden, output = feed_forward(network, inputs[9])\n",
        "print(' '.join('{:.2f}'.format(num) for num in output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00 0.00 0.00 0.01 0.00 0.01 0.00 0.00 0.03 0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPvCyYOFerym"
      },
      "source": [
        "Hooray!  Only the output associated with 4 is close to 1!  The neural network can now correctly identify our inputs.\n",
        "\n",
        "Of course, we tested our neural network with a piece of the training data so it **should** work well.  What if we have an input that is close to, but not quite, our training data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wW7a8rxeryn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74e578d4-2add-43f9-d2ed-6e999099726e"
      },
      "source": [
        "different_three = [0,1,1,1,0, #  *** \n",
        "                   0,0,0,1,1, #    **\n",
        "                   0,0,1,1,0, #   ** \n",
        "                   0,0,0,1,1, #    **\n",
        "                   0,1,1,1,0] #  *** \n",
        "\n",
        "hidden, output = feed_forward(network, different_three)\n",
        "print(' '.join('{:.2f}'.format(num) for num in output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00 0.00 0.00 0.99 0.00 0.00 0.00 0.04 0.00 0.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aPb_6wPeryq"
      },
      "source": [
        "3 is designated as being highly likely but it is (sometimes) not the only one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM_lHlSxeryr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7ae7e88-c9b2-41cc-c21e-c7b57e9a82cc"
      },
      "source": [
        "# Task 5 create a data set for a different 1 and display\n",
        "# the output of the trained network on that set.\n",
        "\n",
        "different_one =   [0,0,1,0,0, #   *\n",
        "                   0,1,1,0,0, #  **\n",
        "                   1,0,1,0,0, # * *\n",
        "                   0,0,1,0,0, #   *\n",
        "                   1,1,1,1,1] # ****** \n",
        "\n",
        "hidden, output = feed_forward(network, different_one)\n",
        "print(' '.join('{:.2f}'.format(num) for num in output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00 0.99 0.42 0.00 0.01 0.00 0.00 0.00 0.00 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ9Stacgeryu"
      },
      "source": [
        "Just for fun, let's make some plots of the weights of the hidden neurons so we can see how they look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KITXZMaOeryu"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_weights(neuron_idx):\n",
        "    weights = network[0][neuron_idx]\n",
        "    abs_weights = [abs(weight) for weight in weights]\n",
        "\n",
        "    grid = [abs_weights[row:(row+5)] # turn the weights into a 5x5 grid\n",
        "            for row in range(0,25,5)] # [weights[0:5], ..., weights[20:25]]\n",
        "\n",
        "    ax = plt.gca() # to use hatching, we'll need the axis\n",
        "\n",
        "    ax.imshow(grid, # here same as plt.imshow\n",
        "              cmap=matplotlib.cm.Blues, # use white-black color scale\n",
        "              interpolation='none') # plot blocks as blocks\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luyzkCdAeryw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a56589d7-289e-4ebc-b001-3f412aba1be4"
      },
      "source": [
        "show_weights(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPoZy4fHeryx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b80c37ad-366b-4fdf-831c-ab2cc4f1725e"
      },
      "source": [
        "show_weights(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wttzu0PSeryz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a159874e-51f0-44f5-e203-a2a15ffbfb88"
      },
      "source": [
        "show_weights(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFEbgQGEEDhRG4EBhBA4URuBAYQQOFPY/4fUJygAbxQkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyScWvE1ery4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "21974810-6f20-4dcd-8c9a-4c5a8f6377c6"
      },
      "source": [
        "show_weights(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACbFJREFUeJzt3U2IXYUdhvH3NYnRJqlRoyiZ0AQq\nlqCoMA1CdgFp/EDdFCLELmoJhUojlYrSld2Wil0IElRsqyiCLkQsEjQiUr/GT4xRSMVqrBDNh4mi\n0ejbxcwi1UzuuZlz5sz99/nBwNzJ5cxLmGfO3DvDuU4iADWd0PcAAN0hcKAwAgcKI3CgMAIHCiNw\noDACBwojcKAwAgcKm9/JQRedkoVLz+ri0K1bMH+0vscd+HhP3xOG8oPTTu17QmPLlizse0Jjez7a\npYP793rQ/ToJfOHSs/STX9/ZxaFbd/aZi/qeMJQn7/xb3xOGcv6Gn/c9obFN61b1PaGxW39xRaP7\njdbpC8BQCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggc\nKKxR4LbX237H9k7bN3c9CkA7BgZue56kOyRdKmm1pGtsr+56GICZa3IGXyNpZ5J3k3wl6UFJV3U7\nC0AbmgS+XNIHR9zeNfUxAHNca0+y2d5ke8L2xOHPP23rsABmoEngH0paccTtsamP/Y8kW5KMJxmf\nv+iUtvYBmIEmgb8k6Rzbq2yfKGmDpEe7nQWgDQOvi57ksO3rJT0haZ6ke5Js73wZgBlr9MIHSR6X\n9HjHWwC0jL9kAwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAw\nAgcKI3CgMAIHCmt0RZdhrVq2SH+/bk0Xh27dk+/u7nvCUNbd/ru+Jwzl/f2H+p7Q2H3Pf+9aonPW\n3s+/bnQ/zuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbg\nQGEEDhRG4EBhAwO3fY/t3bbfnI1BANrT5Ax+r6T1He8A0IGBgSd5RtLeWdgCoGU8BgcKay1w25ts\nT9ie2Lvnk7YOC2AGWgs8yZYk40nGTzt9WVuHBTAD/IgOFNbk12QPSHpO0rm2d9m+rvtZANow8JVN\nklwzG0MAtI8f0YHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwo\njMCBwggcKGzgBR+Ox4effqk/PL6ji0O3buNPl/c9YSgbf/WnvicM5YG7f9/3hMZ+9uPT+57Q2G/v\nXNjofpzBgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHC\nCBwojMCBwgYGbnuF7W2237K93fbm2RgGYOaaXLLpsKQbk7xie4mkl21vTfJWx9sAzNDAM3iSj5K8\nMvX+QUk7JI3WhcyA/1NDPQa3vVLSRZJe6GIMgHY1Dtz2YkkPS7ohyYGj/Psm2xO2Jw4d3NfmRgDH\nqVHgthdoMu77kzxytPsk2ZJkPMn4wiWntrkRwHFq8iy6Jd0taUeS27qfBKAtTc7gayVdK2md7dem\n3i7reBeAFgz8NVmSZyV5FrYAaBl/yQYURuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEE\nDhRG4EBhBA4URuBAYQQOFEbgQGEEDhTW5IUPhrb05Pm6+oIzuzh06/7y5L/6njCcxaf1vWAo/3z/\nexfgnbP+uP7cvic09sOTmqXLGRwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiM\nwIHCCBwojMCBwggcKIzAgcIIHChsYOC2T7L9ou3XbW+3fetsDAMwc02u+3JI0rokn9leIOlZ2/9I\n8nzH2wDM0MDAk0TSZ1M3F0y9pctRANrR6DG47Xm2X5O0W9LWJC90OwtAGxoFnuSbJBdKGpO0xvZ5\n372P7U22J2xPHNy/t+2dAI7DUM+iJ9kvaZuk9Uf5ty1JxpOML1k6Wpf2Bapq8iz6GbaXTr1/sqRL\nJL3d9TAAM9fkWfSzJf3V9jxNfkN4KMlj3c4C0IYmz6K/IemiWdgCoGX8JRtQGIEDhRE4UBiBA4UR\nOFAYgQOFEThQGIEDhRE4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4U1uaLL0E44wVp84oIuDt26\nP199ft8ThvLLfV/2PWEo+7/4uu8Jjf1n3xd9T2jsq2++bXQ/zuBAYQQOFEbgQGEEDhRG4EBhBA4U\nRuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhjQO3Pc/2q7Yf63IQgPYMcwbf\nLGlHV0MAtK9R4LbHJF0u6a5u5wBoU9Mz+O2SbpLU7EpvAOaEgYHbvkLS7iQvD7jfJtsTticO7NvT\n2kAAx6/JGXytpCttvyfpQUnrbN/33Tsl2ZJkPMn4D089veWZAI7HwMCT3JJkLMlKSRskPZVkY+fL\nAMwYvwcHChvqlU2SPC3p6U6WAGgdZ3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwoj\ncKAwAgcKI3CgMAIHCiNwoDACBwojcKAwJ2n/oPbHkv7d8mGXSfqk5WN2aZT2jtJWabT2drX1R0nO\nGHSnTgLvgu2JJON972hqlPaO0lZptPb2vZUf0YHCCBwobJQC39L3gCGN0t5R2iqN1t5et47MY3AA\nwxulMziAIY1E4LbX237H9k7bN/e951hs32N7t+03+94yiO0VtrfZfsv2dtub+940Hdsn2X7R9utT\nW2/te1MTtufZftX2Y318/jkfuO15ku6QdKmk1ZKusb2631XHdK+k9X2PaOiwpBuTrJZ0saTfzOH/\n20OS1iW5QNKFktbbvrjnTU1slrSjr08+5wOXtEbSziTvJvlKk69welXPm6aV5BlJe/ve0USSj5K8\nMvX+QU1+IS7vd9XRZdJnUzcXTL3N6SeQbI9JulzSXX1tGIXAl0v64IjbuzRHvwhHme2Vki6S9EK/\nS6Y39ePua5J2S9qaZM5unXK7pJskfdvXgFEIHB2zvVjSw5JuSHKg7z3TSfJNkgsljUlaY/u8vjdN\nx/YVknYnebnPHaMQ+IeSVhxxe2zqY2iB7QWajPv+JI/0vaeJJPslbdPcfq5jraQrbb+nyYeV62zf\nN9sjRiHwlySdY3uV7RMlbZD0aM+bSrBtSXdL2pHktr73HIvtM2wvnXr/ZEmXSHq731XTS3JLkrEk\nKzX5NftUko2zvWPOB57ksKTrJT2hySeBHkqyvd9V07P9gKTnJJ1re5ft6/redAxrJV2rybPLa1Nv\nl/U9ahpnS9pm+w1NftPfmqSXXz2NEv6SDShszp/BARw/AgcKI3CgMAIHCiNwoDACBwojcKAwAgcK\n+y+vUAOt1JQ/9QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeT9UI9rery6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1568ae81-7d2e-418f-e392-c2bf8ebd51a3"
      },
      "source": [
        "show_weights(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYQQOFEbgQGEEDhRG4EBhBA4U9j+2Fv1/p1dWTwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD93NO3Tery-"
      },
      "source": [
        "It looks like our hidden neurons 1 and 3 would both fire strongly on inputs[1] since they are sensitive to central, vertical pixels.  Let's see if we are right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwaC4o5eery_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fe46abd-d6c6-4b3e-fe09-30d87ffa1da5"
      },
      "source": [
        "hidden, output = feed_forward(network, inputs[1])\n",
        "print(hidden)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0001848992833641413, 0.9995057778648715, 0.9997038490884612, 0.9993306164826646, 0.7173676990713651]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJTupK_qerzB"
      },
      "source": [
        "Hey, we were right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGiFKupperzH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7cab77c-d523-45e0-9fbe-8513c541451b"
      },
      "source": [
        "# Task 6: Make a prediction for which hidden layer neurons \n",
        "# will fire strongly for inputs[7].  Run the network on\n",
        "# this input and print the hidden layer outputs\n",
        "\n",
        "hidden, output = feed_forward(network, inputs[7])\n",
        "print(hidden)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.6682748491307504e-09, 0.9993146463418915, 0.08703816693214435, 0.9998023404893324, 1.115510073774802e-06]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}